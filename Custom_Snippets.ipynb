{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Rpru_VOJN6o9"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tamtemtomm/kaggle-notebooks/blob/main/Custom_Snippets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Kaggle Input"
      ],
      "metadata": {
        "id": "Rpru_VOJN6o9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3> Kaggle Authentication"
      ],
      "metadata": {
        "id": "sWMEkKJePE7S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle"
      ],
      "metadata": {
        "id": "1NbJ9C8VOS6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title <p> Import kaggle API\n",
        "# from google.colab import files\n",
        "# files.upload()\n",
        "\n",
        "# ! mkdir ~/.kaggle\n",
        "# ! cp kaggle.json ~/.kaggle\n",
        "# ! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "o2CIywIAOOuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_aaM51XgMvVb"
      },
      "outputs": [],
      "source": [
        "# @title <p>Import kaggle API from google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "! mkdir ~/.kaggle\n",
        "! cp '/content/gdrive/MyDrive/Colab Notebooks/kaggle.json' ~/.kaggle\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "drive.flush_and_unmount()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title <p>Download Dataset\n",
        "!kaggle datasets download '...........'\n",
        "!unzip '...........' &> /dev/null\n",
        "!rm '...........'"
      ],
      "metadata": {
        "id": "TSA1lDcDPcZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Essential Import"
      ],
      "metadata": {
        "id": "254cq225QDcQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title <p>Essential Import\n",
        "import os, shutil, json\n",
        "from PIL import Image\n",
        "from zipfile import ZipFile\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np, pandas as pd, random as rd\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "x-EPbNoVQGIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Torch Essential Import"
      ],
      "metadata": {
        "id": "RJoAG7HJQ1mD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title <p>Torch Essential Import\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as T\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "torch.manual_seed(0)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "wfMN-fO8Qw8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Torch MNIST Datasets Import"
      ],
      "metadata": {
        "id": "G-uLIGymHUwF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "transforms = T.ToTensor()\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transforms, download=True)\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transforms, download=True)\n",
        "\n",
        "# Image test\n",
        "print(f'Class : {train_dataset[0][1]}')\n",
        "plt.imshow(train_dataset[0][0].permute(1, 2, 0))"
      ],
      "metadata": {
        "id": "daeGUmqaHekv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sklearn Essential Import"
      ],
      "metadata": {
        "id": "8b_bwibbSY0K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title <p>Sklearn Essential Import\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
        "from sklearn.metrics import confusion_matrix, multilabel_confusion_matrix, recall_score, precision_score, accuracy_score, f1_score, classification_report\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from xgboost import XGBClassifier"
      ],
      "metadata": {
        "id": "rDCH9QBqSmYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Audio Exploration Essential Function"
      ],
      "metadata": {
        "id": "bCamB1ouWjgC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title <p> Audio Exploration Essential Function\n",
        "import librosa\n",
        "import IPython.display as ipd\n",
        "import torchaudio.transforms as T2\n",
        "\n",
        "def wav2mel(wav_path):\n",
        "  waveform, sr = librosa.load(wav_path)\n",
        "  return librosa.feature.melspectrogram(y=waveform, sr=sr)\n",
        "\n",
        "def imgspec(ms_feature):\n",
        "  print(ms_feature.shape)\n",
        "  fig, ax = plt.subplots()\n",
        "  ms_db = librosa.power_to_db(ms_feature, ref = np.max)\n",
        "  img = librosa.display.specshow(ms_db, x_axis='time', y_axis='mel', ax=ax)\n",
        "  fig.colorbar(img, ax=ax, format='%+2.0f dB')\n",
        "  ax.set(title='Mel-frequency spectrogram')\n",
        "\n",
        "def hear_audio(wav_path):\n",
        "  audio, sr = librosa.load(wav_path)\n",
        "  print(\"\\t\", end=\"\")\n",
        "  ipd.display(ipd.Audio(data=audio, rate=sr))\n",
        "\n",
        "def audio_info(wav_path, show_melspec=False, label=None):\n",
        "    spec = wav2mel(wav_path)\n",
        "    if label is not None:\n",
        "        print(\"Label:\", label)\n",
        "    if show_melspec is not False:\n",
        "        imgspec(spec)\n",
        "    hear_audio(wav_path)"
      ],
      "metadata": {
        "id": "TuCmoD-vW_K2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}